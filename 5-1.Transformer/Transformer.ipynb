{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows end of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = [\n",
    "        # enc_input           dec_input         dec_output\n",
    "        ['ich mochte ein bier P', 'S i want a beer .', 'i want a beer . E'],\n",
    "        ['ich mochte ein cola P', 'S i want a coke .', 'i want a coke . E']\n",
    "]\n",
    "\n",
    "# Padding Should be Zero\n",
    "src_vocab = {'P' : 0, 'ich' : 1, 'mochte' : 2, 'ein' : 3, 'bier' : 4, 'cola' : 5}\n",
    "src_vocab_size = len(src_vocab)\n",
    "\n",
    "tgt_vocab = {'P' : 0, 'i' : 1, 'want' : 2, 'a' : 3, 'beer' : 4, 'coke' : 5, 'S' : 6, 'E' : 7, '.' : 8}\n",
    "idx2word = {i: w for i, w in enumerate(tgt_vocab)}\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "\n",
    "src_len = 5 # enc_input max sequence length\n",
    "tgt_len = 6 # dec_input(=dec_output) max sequence length\n",
    "\n",
    "def make_data(sentences):\n",
    "    enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
    "    for i in range(len(sentences)):       \n",
    "      enc_input = [src_vocab[n] for n in sentences[i][0].split()]\n",
    "      dec_input = [tgt_vocab[n] for n in sentences[i][1].split()]\n",
    "      dec_output = [tgt_vocab[n] for n in sentences[i][2].split()]\n",
    "      enc_inputs.append(enc_input)\n",
    "      dec_inputs.append(dec_input)\n",
    "      dec_outputs.append(dec_output)\n",
    "    return torch.LongTensor(enc_inputs), torch.LongTensor(dec_inputs), torch.LongTensor(dec_outputs)\n",
    "\n",
    "enc_inputs, dec_inputs, dec_outputs = make_data(sentences)\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "  def __init__(self, enc_inputs, dec_inputs, dec_outputs):\n",
    "    super(MyDataSet, self).__init__()\n",
    "    self.enc_inputs = enc_inputs\n",
    "    self.dec_inputs = dec_inputs\n",
    "    self.dec_outputs = dec_outputs\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.enc_inputs.shape[0]\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.enc_inputs[idx], self.dec_inputs[idx], self.dec_outputs[idx]\n",
    "\n",
    "loader = Data.DataLoader(MyDataSet(enc_inputs, dec_inputs, dec_outputs), 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 0]]) tensor([[6, 1, 2, 3, 4, 8]]) tensor([[1, 2, 3, 4, 8, 7]])\n",
      "tensor([[1, 2, 3, 5, 0]]) tensor([[6, 1, 2, 3, 5, 8]]) tensor([[1, 2, 3, 5, 8, 7]])\n"
     ]
    }
   ],
   "source": [
    "for enc_inputs, dec_inputs, dec_outputs in loader:\n",
    "  print(enc_inputs, dec_inputs, dec_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PE : tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "\n",
      "After PE : tensor([[[0.0000, 1.1111, 0.0000, 1.1111],\n",
      "         [0.9350, 0.0000, 0.0111, 1.1111]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pe = PositionalEncoding(4)\n",
    "a = torch.zeros(1, 2, 4)\n",
    "print (f'Before PE : {a}\\n')\n",
    "b = pe(a)\n",
    "print (f'After PE : {b}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # [batch_size, 1, len_k], False is masked\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # [batch_size, len_q, len_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True]]])\n",
      "tensor([[[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True]]])\n"
     ]
    }
   ],
   "source": [
    "seq_k = torch.tensor([[1, 2, 3, 5, 0]])\n",
    "print(get_attn_pad_mask(seq_k, seq_k))\n",
    "seq_q = torch.tensor([[6, 1, 2, 3, 5, 8]])\n",
    "print(get_attn_pad_mask(seq_q, seq_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequence_mask(seq):\n",
    "    '''\n",
    "    seq: [batch_size, tgt_len]\n",
    "    '''\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape), k=1) # Upper triangular matrix\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()\n",
    "    return subsequence_mask # [batch_size, tgt_len, tgt_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 1],\n",
      "         [0, 0, 0, 1, 1],\n",
      "         [0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0]]], dtype=torch.uint8)\n",
      "tensor([[[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True]]])\n",
      "tensor([[[False,  True,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [False, False, False,  True,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True]]])\n"
     ]
    }
   ],
   "source": [
    "seq = torch.tensor([[1, 2, 3, 5, 0]])\n",
    "a=get_attn_subsequence_mask(seq)\n",
    "print(a)\n",
    "b=get_attn_pad_mask(seq, seq)\n",
    "print(b)\n",
    "c = torch.gt((a + b), 0) #Decoder 中不仅要把 \"pad\"mask 掉，还要 mask 未来时刻的信息。\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask):\n",
    "        residual, bs = q, q.size(0)  \n",
    "        # perform linear operation and split into h heads    \n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * h * seq_len * d_k      \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "\n",
    "        #print(f'k shape -{k.shape}')\n",
    "        #print('-------------')\n",
    "        #print(f'q shape -{q.shape}')\n",
    "        #print('-------------')\n",
    "        #print(f'v shape -{v.shape}')\n",
    "        #print('-------------')\n",
    "\n",
    "        mask = mask.unsqueeze(1).repeat(1, self.h, 1, 1)\n",
    "        #print(f'mask shape -{mask.shape}, mask = {mask}\\n')\n",
    "        #print('-------------')\n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        \n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).reshape(bs, -1, self.d_model)\n",
    "        #print(f'concat shape -{concat.shape}\\n')\n",
    "        #print('-------------')        \n",
    "        output = self.out(concat)\n",
    "        output = nn.LayerNorm(self.d_model)(output + residual)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def attention(q, k, v, d_k, mask, dropout=None):    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    #print(f'scores shape -{scores.shape}\\n')\n",
    "    #print('-------------')\n",
    "\n",
    "    scores.masked_fill_(mask, -1e9)\n",
    "    #print(f'masked scores shape -{scores.shape}, masked scores = {scores}\\n')\n",
    "    #print('-------------')\n",
    "\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    #print(f'softmax scores shape -{scores.shape}, softmax scores = {scores}\\n')\n",
    "    #print('-------------')\n",
    "\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    #print(f'attention output shape -{output.shape}\\n')\n",
    "    #print('-------------') \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - 全连接前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.d_ff, self.d_model)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        inputs: [batch_size, seq_len, d_model]\n",
    "        '''\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return nn.LayerNorm(self.d_model)(output + residual) # [batch_size, seq_len, d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Encoder部分数据流动过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_inputs = tensor([[1, 2, 3, 5, 0]])\n",
      "\n",
      "enc_outputs shape = torch.Size([1, 5, 4])\n",
      "\n",
      "enc_self_attn_mask shape - torch.Size([1, 5, 5]), enc_self_attn_mask = tensor([[[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True]]])\n",
      "\n",
      "k shape -torch.Size([1, 2, 5, 2])\n",
      "-------------\n",
      "q shape -torch.Size([1, 2, 5, 2])\n",
      "-------------\n",
      "v shape -torch.Size([1, 2, 5, 2])\n",
      "-------------\n",
      "mask shape -torch.Size([1, 2, 5, 5]), mask = tensor([[[[False, False, False, False,  True],\n",
      "          [False, False, False, False,  True],\n",
      "          [False, False, False, False,  True],\n",
      "          [False, False, False, False,  True],\n",
      "          [False, False, False, False,  True]],\n",
      "\n",
      "         [[False, False, False, False,  True],\n",
      "          [False, False, False, False,  True],\n",
      "          [False, False, False, False,  True],\n",
      "          [False, False, False, False,  True],\n",
      "          [False, False, False, False,  True]]]])\n",
      "\n",
      "-------------\n",
      "scores shape -torch.Size([1, 2, 5, 5])\n",
      "\n",
      "-------------\n",
      "masked scores shape -torch.Size([1, 2, 5, 5]), masked scores = tensor([[[[ 1.3839e+00,  1.3054e+00,  2.0933e-01,  6.2322e-01, -1.0000e+09],\n",
      "          [ 3.7884e-01,  5.7561e-01,  1.7839e-01,  4.5866e-01, -1.0000e+09],\n",
      "          [ 3.0580e-01, -6.1165e-03, -1.1717e-01, -2.5107e-01, -1.0000e+09],\n",
      "          [-3.3883e-01, -2.3862e-01, -6.3137e-03, -4.5685e-02, -1.0000e+09],\n",
      "          [ 1.7289e-01,  1.1044e+00,  5.4841e-01,  1.3202e+00, -1.0000e+09]],\n",
      "\n",
      "         [[-2.4239e-01, -1.7683e-01, -2.7524e-01, -1.6366e-01, -1.0000e+09],\n",
      "          [ 1.5631e-01, -5.8464e-01,  3.6280e-02, -5.8544e-01, -1.0000e+09],\n",
      "          [-4.2010e-01, -4.7591e-01, -5.1126e-01, -4.5121e-01, -1.0000e+09],\n",
      "          [ 6.7133e-02, -7.1550e-01, -7.8277e-02, -7.1073e-01, -1.0000e+09],\n",
      "          [ 9.4795e-01,  2.0355e-02,  9.4074e-01, -2.3791e-02, -1.0000e+09]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "\n",
      "-------------\n",
      "softmax scores shape -torch.Size([1, 2, 5, 5]), softmax scores = tensor([[[[0.3703, 0.3423, 0.1144, 0.1730, 0.0000],\n",
      "          [0.2428, 0.2956, 0.1987, 0.2630, 0.0000],\n",
      "          [0.3378, 0.2473, 0.2213, 0.1936, 0.0000],\n",
      "          [0.2066, 0.2284, 0.2881, 0.2770, 0.0000],\n",
      "          [0.1228, 0.3117, 0.1787, 0.3868, 0.0000]],\n",
      "\n",
      "         [[0.2429, 0.2593, 0.2350, 0.2628, 0.0000],\n",
      "          [0.3521, 0.1678, 0.3123, 0.1677, 0.0000],\n",
      "          [0.2612, 0.2471, 0.2385, 0.2532, 0.0000],\n",
      "          [0.3595, 0.1644, 0.3109, 0.1652, 0.0000],\n",
      "          [0.3614, 0.1429, 0.3588, 0.1368, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "\n",
      "-------------\n",
      "attention output shape -torch.Size([1, 2, 5, 2])\n",
      "\n",
      "-------------\n",
      "concat shape -torch.Size([1, 5, 4])\n",
      "\n",
      "-------------\n",
      "fnn output shape - torch.Size([1, 5, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_d_model = 4\n",
    "tmp_n_heads = 2\n",
    "tmp_d_ff = 6\n",
    "torch.manual_seed(1) \n",
    "\n",
    "#enc_inputs：[batch_size, seq_len]\n",
    "enc_inputs, dec_inputs, dec_outputs = next(iter(loader))\n",
    "print (f'enc_inputs = {enc_inputs}\\n')\n",
    "\n",
    "#转换为词向量形式 enc_outputs：[batch_size, seq_len, d_model]\n",
    "enc_outputs = nn.Embedding(src_vocab_size, tmp_d_model)(enc_inputs)\n",
    "\n",
    "#词向量基础上+位置向量 enc_outputs：[batch_size, seq_len, d_model]\n",
    "enc_outputs = PositionalEncoding(tmp_d_model)(enc_outputs)\n",
    "print (f'enc_outputs shape = {enc_outputs.shape}\\n')\n",
    "\n",
    "#pad mask\n",
    "enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) \n",
    "print (f'enc_self_attn_mask shape - {enc_self_attn_mask.shape}, enc_self_attn_mask = {enc_self_attn_mask}\\n')\n",
    "\n",
    "#Attention\n",
    "att_test = MultiHeadAttention(tmp_n_heads, tmp_d_model)\n",
    "out = att_test(enc_outputs, enc_outputs, enc_outputs, enc_self_attn_mask)\n",
    "\n",
    "#FFN\n",
    "ffn_test = PoswiseFeedForwardNet(tmp_d_model, tmp_d_ff)\n",
    "#最终的输出向量 out：[batch_size, seq_len, d_model]\n",
    "out = ffn_test(out)\n",
    "print (f'fnn output shape - {out.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder 一共有 N=6 个 encoderlayer 堆叠在一起，每个 encoderlayer 由两个子层组成。第一个子层实现了“多头”的 Encoder Self-attention，对应如上的 MultiHeadAttention，第二个子层则是个简单的 Position-wise 的全连接前馈网络，对应如上的 PoswiseFeedForwardNet。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, heads, d_model, d_ff):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(heads, d_model)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        '''\n",
    "        enc_outputs = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)# enc_outputs: [batch_size, src_len, d_model]\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终的 Encoder 就是这 N=6 个 encoderlayer 堆叠在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, src_vocab_size, heads, d_model, d_ff, n_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(heads, d_model, d_ff) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        '''\n",
    "        enc_outputs = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "        enc_outputs = self.pos_emb(enc_outputs) # [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n",
    "        for layer in self.layers:\n",
    "            # enc_outputs: [batch_size, src_len, d_model]\n",
    "            enc_outputs = layer(enc_outputs, enc_self_attn_mask)\n",
    "        return enc_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比较于 Encoder, Decoder 多经过了一层 Decoder-Encoder Attention 的计算， 并且在计算 Decoder Self-attention 的时候不仅要把 \"pad\" mask 掉，还要 mask 未来时刻的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, heads, d_model, d_ff):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(heads, d_model)\n",
    "        self.dec_enc_attn = MultiHeadAttention(heads, d_model)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        dec_enc_attn_mask: [batch_size, tgt_len, src_len]\n",
    "        '''\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs) # [batch_size, tgt_len, d_model]\n",
    "        return dec_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, tgt_vocab_size, heads, d_model, d_ff, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(heads, d_model, d_ff) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        enc_outputs: [batsh_size, src_len, d_model]\n",
    "        '''\n",
    "        dec_outputs = self.tgt_emb(dec_inputs) # [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = self.pos_emb(dec_outputs) # [batch_size, tgt_len, d_model]\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs) # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_subsequence_mask = get_attn_subsequence_mask(dec_inputs) # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask), 0) # [batch_size, tgt_len, tgt_len]\n",
    "\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs) # [batc_size, tgt_len, src_len]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "            dec_outputs = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "        return dec_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, heads, d_model, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, heads, d_model, d_ff, n_layers)\n",
    "        self.decoder = Decoder(tgt_vocab_size, heads, d_model, d_ff, n_layers)\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        '''\n",
    "        # enc_outputs: [batch_size, src_len, d_model]\n",
    "        enc_outputs = self.encoder(enc_inputs)\n",
    "        # dec_outpus: [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "        dec_logits = self.projection(dec_outputs)\n",
    "        return dec_logits.view(-1, dec_logits.size(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 - 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 2.585765\n",
      "Epoch: 0001 loss = 2.383128\n",
      "Epoch: 0002 loss = 2.237804\n",
      "Epoch: 0002 loss = 1.937003\n",
      "Epoch: 0003 loss = 1.893852\n",
      "Epoch: 0003 loss = 1.589763\n",
      "Epoch: 0004 loss = 1.499871\n",
      "Epoch: 0004 loss = 1.345889\n",
      "Epoch: 0005 loss = 1.184624\n",
      "Epoch: 0005 loss = 1.183304\n",
      "Epoch: 0006 loss = 0.806398\n",
      "Epoch: 0006 loss = 0.864008\n",
      "Epoch: 0007 loss = 0.704574\n",
      "Epoch: 0007 loss = 0.486642\n",
      "Epoch: 0008 loss = 0.502043\n",
      "Epoch: 0008 loss = 0.264302\n",
      "Epoch: 0009 loss = 0.258390\n",
      "Epoch: 0009 loss = 0.302220\n",
      "Epoch: 0010 loss = 0.180751\n",
      "Epoch: 0010 loss = 0.235268\n",
      "Epoch: 0011 loss = 0.178867\n",
      "Epoch: 0011 loss = 0.122559\n",
      "Epoch: 0012 loss = 0.147611\n",
      "Epoch: 0012 loss = 0.138665\n",
      "Epoch: 0013 loss = 0.115273\n",
      "Epoch: 0013 loss = 0.098724\n",
      "Epoch: 0014 loss = 0.078117\n",
      "Epoch: 0014 loss = 0.066898\n",
      "Epoch: 0015 loss = 0.072905\n",
      "Epoch: 0015 loss = 0.085518\n",
      "Epoch: 0016 loss = 0.136289\n",
      "Epoch: 0016 loss = 0.055864\n",
      "Epoch: 0017 loss = 0.083160\n",
      "Epoch: 0017 loss = 0.043318\n",
      "Epoch: 0018 loss = 0.056979\n",
      "Epoch: 0018 loss = 0.057976\n",
      "Epoch: 0019 loss = 0.074648\n",
      "Epoch: 0019 loss = 0.032765\n",
      "Epoch: 0020 loss = 0.033892\n",
      "Epoch: 0020 loss = 0.049689\n",
      "Epoch: 0021 loss = 0.050020\n",
      "Epoch: 0021 loss = 0.038318\n",
      "Epoch: 0022 loss = 0.061914\n",
      "Epoch: 0022 loss = 0.064269\n",
      "Epoch: 0023 loss = 0.029807\n",
      "Epoch: 0023 loss = 0.048840\n",
      "Epoch: 0024 loss = 0.036034\n",
      "Epoch: 0024 loss = 0.064244\n",
      "Epoch: 0025 loss = 0.023727\n",
      "Epoch: 0025 loss = 0.018975\n",
      "Epoch: 0026 loss = 0.028525\n",
      "Epoch: 0026 loss = 0.015815\n",
      "Epoch: 0027 loss = 0.017258\n",
      "Epoch: 0027 loss = 0.023306\n",
      "Epoch: 0028 loss = 0.013564\n",
      "Epoch: 0028 loss = 0.012689\n",
      "Epoch: 0029 loss = 0.005434\n",
      "Epoch: 0029 loss = 0.023077\n",
      "Epoch: 0030 loss = 0.016120\n",
      "Epoch: 0030 loss = 0.005493\n"
     ]
    }
   ],
   "source": [
    "d_model = 256\n",
    "n_heads = 8\n",
    "d_ff = 2048\n",
    "n_layers = 6\n",
    "src_vocab_size = 6\n",
    "tgt_vocab_size = 9\n",
    "\n",
    "model = Transformer(src_vocab_size, tgt_vocab_size, n_heads, d_model, d_ff, n_layers)\n",
    "#for p in model.parameters():\n",
    "#    if p.dim() > 1:\n",
    "#        nn.init.xavier_uniform_(p)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)\n",
    "\n",
    "for epoch in range(30):\n",
    "    for enc_inputs, dec_inputs, dec_outputs in loader:\n",
    "      '''\n",
    "      enc_inputs: [batch_size, src_len]\n",
    "      dec_inputs: [batch_size, tgt_len]\n",
    "      dec_outputs: [batch_size, tgt_len]\n",
    "      '''\n",
    "      enc_inputs, dec_inputs, dec_outputs = enc_inputs, dec_inputs, dec_outputs\n",
    "      # outputs: [batch_size * tgt_len, tgt_vocab_size]\n",
    "      outputs = model(enc_inputs, dec_inputs)\n",
    "      loss = criterion(outputs, dec_outputs.view(-1))\n",
    "      print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want a coke .\n"
     ]
    }
   ],
   "source": [
    "def greedy_decoder(model, enc_input, tgt_len = 6, idx2word=idx2word, start_symbol=tgt_vocab[\"S\"]):\n",
    "    \"\"\"\n",
    "    For simplicity, a Greedy Decoder is Beam search when K=1. This is necessary for inference as we don't know the\n",
    "    target sequence input. Therefore we try to generate the target input word by word, then feed it into the transformer.\n",
    "    Starting Reference: http://nlp.seas.harvard.edu/2018/04/03/attention.html#greedy-decoding\n",
    "    :param model: Transformer Model\n",
    "    :param enc_input: The encoder input\n",
    "    :param start_symbol: The start symbol.\n",
    "    :return: The target input\n",
    "    \"\"\"\n",
    "    enc_outputs = model.encoder(enc_input)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.LongTensor)\n",
    "    out = []\n",
    "    for i in range(0, tgt_len):\n",
    "        dec_outputs = model.decoder(ys, enc_input, enc_outputs)\n",
    "        projected = model.projection(dec_outputs).squeeze(0)[-1]\n",
    "        #print(projected)\n",
    "        ind = torch.max(projected, dim=-1)[1].data.item()\n",
    "        #print(ind)\n",
    "        #print('----------')\n",
    "        \n",
    "        next_word = idx2word[ind]\n",
    "        if next_word == 'E':\n",
    "            break\n",
    "        \n",
    "        out.append(next_word)\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).fill_(ind).type(torch.LongTensor)], dim=1)\n",
    "        #print(out)\n",
    "        #print(ys)\n",
    "        #print('===========')\n",
    "    return ' '.join(out)\n",
    "\n",
    "# Test\n",
    "enc_inputs, _, _ = next(iter(loader))\n",
    "greedy_dec_input = greedy_decoder(model, enc_inputs[0].view(1, -1))\n",
    "print(greedy_dec_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
